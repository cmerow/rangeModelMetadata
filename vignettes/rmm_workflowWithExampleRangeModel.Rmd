---
title: "An example workflow for building rangeModelMetadata objects"
author: "Jamie Kass, Cory Merow, Brian Maitner, Hannah Owens, Brian Enquist, Rob Guralnick"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    fig_caption: yes
    toc: true
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{An example workflow for building rangeModelMetadata objects}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = FALSE)

```

```{r,results='hide',message=FALSE}
library(rangeModelMetadata)
library(rgbif)
library(raster)
library(dismo)
library(ENMeval)
library(dplyr)
library(sp)
library(spThin)
library(jsonlite)
```

# Building a range model
## Get data
```{r}
# search GBIF for occurrence data
bv <- rgbif::occ_search(scientificName ='Bradypus variegatus')
# restrict table to coordinates
occs=dplyr::select(bv$data, decimalLongitude, decimalLatitude)
# remove duplicate values
occs <- occs[!duplicated(occs),]
# get environmental rasters from dismo package folder
files <- list.files(path=paste(system.file(package='dismo'), '/ex',
                               sep=''), pattern='grd', full.names=TRUE)
# make a stack of the rasters
envs <- raster::stack(files)
```

<!-- bv <- spocc::occ('Bradypus variegatus', 'gbif', limit=300, has_coords=TRUE) -->
<!-- occs=dplyr::select(bv$gbif$data$Bradypus_variegatus, longitude, latitude) -->

<!-- # remove correlated predictors -->
<!-- (cors=layerStats(envs, 'pearson', na.rm=T)[[1]]) -->
<!-- envs=envs[[c('bio1','bio7','bio12','bio16')]] -->
<!-- (cors=layerStats(envs, 'pearson', na.rm=T)[[1]]) -->


## Prepare data

```{r}
# thin points to remove spatial autocorrelation
occs.thinned <- spThin::thin.algorithm(data.frame(occs), thin.par=20, reps=1)
# make a spatial points object for the occurrences
occs.sp <- sp::SpatialPoints(occs.thinned[[1]])
# get the bounding box
bb <- sp::bbox(occs.sp)
# make extent object and buffer by 5 degrees
bb.buf <- raster::extent(bb[1]-5, bb[3]+5, bb[2]-5, bb[4]+5)
# crop environmental rasters by the extent to make the background extent
bg.ext <- raster::crop(envs, bb.buf)
# generate up to 10,000 random points within the background extent (we'll sample from the "biome" raster as it has more holes)
bg <- dismo::randomPoints(bg.ext[[4]], n=10000) 
```

## Model Fitting

```{r}
# run ENMeval
e <- ENMeval::ENMevaluate(occs, bg.ext, bg, method='block', RMvalues=1:3, fc=c('L','LQ'), algorithm='maxent.jar')
```

## Model evaluation
```{r}
# find the index number of the model with the highest mean test AUC: this will be the optimal model
i <- which(e@results$avg.test.AUC  == max(e@results$avg.test.AUC ))
# extract the optimal model object
m <- e@models[[i]]
```

## Predictions
```{r}
# create a cloglog prediction and plot
#p <- predict(m, bg.ext, args=c("outputformat=cloglog"))
notNA <- complete.cases(values(bg.ext))
tmp <- predict(m, values(bg.ext)[notNA,], type='link')
p <- bg.ext[[1]] 
values(p) <- NA 
values(p)[notNA] <- tmp
plot(p)
# further south extent for model transfer
t.bb <- raster::extent(-80,-40,-60,-30)
# crop environmental predictors by transfer extent
t.ext <- raster::crop(envs, t.bb)
```

## Transfer model
```{r}
# transfer the model to this new area and plot
notNA.t <- complete.cases(values(t.ext))
tmp <- predict(m, values(t.ext)[notNA.t,], type='link')
p.t <- t.ext[[1]] 
values(p.t) <- NA 
values(p.t)[notNA.t] <- tmp
plot(p.t)
```

# Build an `rmm` object

Begin by choosing a few families of fields relevant for this analysis and making a template. This will generate all the recommended fields, although the only fields that you must fill in are in `base`.
```{r}
# generate an empty range model metadata template
rmm=rmmTemplate(family=c('base','dataPrep','maxent','prediction',
                         'transferEnv1','binaryClassification'))
```

Note that to see a little bit less detail, it's useful to use 

```{r}
str(rmm,1)
```
or 
```{r}
str(rmm,2)
```

## Authorship

We start by filling in some key authorship information.
```{r}
  # in the form Author_Year_Taxa_Model_fw (where the last 2 characters are random)
rmm$authorship$rmmName='MerowMaitnerOwensKassEnquistGuralnick_2018_BradypusVariegatus_Maxent_b3'
  # names are distinct from citations (below) in case a citation does not exist 
rmm$authorship$names='Merow, Cory and Maitner, Brian and Owens, Hannah and Kass, Jamie and Enquist, Brian and Guralnick, Rob'
rmm$authorship$contact='cory.merow@gmail.com'
rmm$authorship$relatedReferences='@article{, title={RMMS: Species’ Range Model Metadata Standards },author={Merow, Cory and Maitner, Brian and Owens, Hannah and Kass, Jamie and Enquist, Brian and Guralnick, Rob},journal={Global Ecology and Biogeography},year={2018}}'
rmm$authorship$license='CC'
rmm$authorship$miscNotes='Funding from NSF grant DBI-1661510 and DBI-1913673.'
```
<!-- Would be nice to show how to make this a formal citation class, but i don't knowhow: -->
<!-- ref='@article{, title={RMMS: Species’ Range Model Metadata Standards },author={Merow, Cory and Maitner, Brian and Owens, Hannah and Kass, Jamie and Enquist, Brian and Guralnick, Rob},journal={Unknown},year={2018}, publisher={Unknown}}' -->
<!-- as(ref,'citation') -->


## Autofill when possible
To make it easier to fill some `rmm` fields, we provide autofill functions that extract relevant information from common R objects used in the 

```{r}
# occurrence data
rmm <- rmmAutofillspocc(rmm, bv$gbif) 
# autofill info for environmental rasters used for model training and transfer
rmm <- rmmAutofillEnvironment(rmm, bg.ext, transfer=0) 
rmm <- rmmAutofillEnvironment(rmm, t.ext, transfer=1)
# autofill for ENMeval
rmm <- rmmAutofillENMeval(rmm, e, 
                          selectionCriteria="highest mean test AUC",
                          optimalModelIndex=i) 
# R packages used
rmm <- rmmAutofillPackageCitation(rmm=rmm,
                                  packages= c('rgbif','sp','raster','dismo','ENMeval'))
```  

## Data 
Now we need to fill in a few fields manually. 

```{r}
rmm$data$occurrence$sources=lapply(rgbif::gbif_citation(bv),function(x) x$citation$citation)
rmm$data$occurrence$presenceSampleSize=length(occs.sp)
rmm$data$occurrence$backgroundSampleSize=nrow(bg)
rmm$data$occurrence$yearMin=1970
rmm$data$occurrence$yearMax=2000
```

Note that in the use of `gbif_citation` above, we use a journal formatted style for references, instead of bibtex, as used below. We chose this because the journal formatting is returned by `gbif_citation` and bibtex it not available. Rather than request that authors spend an inordinate amount of time manually reformatting perfectly good citations (which is error prone) we suggest simply using this default format. 

```{r}
rmm$data$environment$yearMin=1970
rmm$data$environment$yearMin=2000
rmm$data$environment$sources='
@ARTICLE{Fick2017-qs,
  title     = "{WorldClim} 2: new 1‐km spatial resolution climate surfaces for
               global land areas",
  author    = "Fick, S E and Hijmans, R J",
  abstract  = "We created a new dataset of spatially interpolated monthly
               climate data for global land areas at a very high spatial
               resolution (approximately 1 km 2). We included monthly
               temperature (minimum, maximum and average), precipitation, solar
               radiation, vapour pressure and wind speed, aggregated across a
               target temporal range of 1970--2000, using data from between
               9000 and 60 000 weather stations. Weather station data were
               interpolated using thin-plate splines with covariates including
               elevation, distance to the coast and three satellite-derived …",
  journal   = "Int. J. Climatol.",
  publisher = "Wiley Online Library",
  year      =  2017
}
'
rmm$data$dataNotes='WorldClim data accessed through dismo v1.1-4'
```


To fill in the min and max values of each data layer, it's easiest to create a `data.frame` and convert that to JSON. 
```{r}
mm=data.frame(rbind(apply(values(envs),2,min,na.rm=T),
                    apply(values(envs),2,max,na.rm=T)))
rmm$data$environment$minVal=toJSON(mm[1,])
(rmm$data$environment$maxVal=toJSON(mm[2,])) # printed to show format
```

To fill in the extent of the layers, you can either do it manually or programatically. I do it programatically because I think it's easier to make it JSON format.

```{r}
(ex=extent(envs))
# make an extent object a data.frame, because that's easy to use with toJSON
tmp=as.data.frame(lapply(slotNames(ex), function(i) slot(ex, i) )) 
names(tmp)=slotNames(ex)
rmm$data$environment$extentSet=toJSON(tmp)
```

Have I missed anything?
```{r}
rmmSuggest('$data') # note the use of quotes!
```
Oh yeah, we haven't dealt with the environment to which the model is transferred. In the modeling above we transferred to an adjacent region. So this follows analogous information provided for the fitting layers.


```{r}
rmm$data$transfer$environment1$yearMin=1970
rmm$data$transfer$environment1$yearMin=2000
rmm$data$transfer$environment1$resolution=paste0(res(t.ext)[1],' degrees')
rmm$data$transfer$environment1$sources='
@ARTICLE{Fick2017-qs,
  title     = "{WorldClim} 2: new 1‐km spatial resolution climate surfaces for
               global land areas",
  author    = "Fick, S E and Hijmans, R J",
  abstract  = "We created a new dataset of spatially interpolated monthly
               climate data for global land areas at a very high spatial
               resolution (approximately 1 km 2). We included monthly
               temperature (minimum, maximum and average), precipitation, solar
               radiation, vapour pressure and wind speed, aggregated across a
               target temporal range of 1970--2000, using data from between
               9000 and 60 000 weather stations. Weather station data were
               interpolated using thin-plate splines with covariates including
               elevation, distance to the coast and three satellite-derived …",
  journal   = "Int. J. Climatol.",
  publisher = "Wiley Online Library",
  year      =  2017
}
'

mm=data.frame(rbind(apply(values(t.ext),2,min,na.rm=T),
                    apply(values(t.ext),2,max,na.rm=T)))
rmm$data$transfer$environment1$minVal=toJSON(mm[1,])
(rmm$data$transfer$environment1$maxVal=toJSON(mm[2,])) # printed to show format

(ex=extent(t.ext))
# make an extent object a data.frame, because that's easy to use with toJSON
tmp=as.data.frame(lapply(slotNames(ex), function(i) slot(ex, i) )) 
names(tmp)=slotNames(ex)
rmm$data$transfer$environment1$extentSet=toJSON(tmp)
```

## Data Preparation (cleaning)

```{r}
# duplicated observations removed within the grid cells defined by the environmental layers
rmm$dataPrep$biological$duplicateRemoval$rule='cell' 
rmm$dataPrep$geographic$spatialThin$rule= "20km used as max distance between points"
```

## Model Fitting 
```{r}

```


## Prediction

```{r}
# fill in remaining fields for model prediction in background extent
rmm$prediction$continous$units <- "relative occurrence rate"
rmm$prediction$continous$minVal <- cellStats(p, min)
rmm$prediction$continous$maxVal <- cellStats(p, max)
# clamping is the default for predict()
rmm$prediction$extrapolation <- "clamping"
```

## Evaluation
```{r}

```

## Code

```{r}

```


## Check your `rmm` object

Let's see how we're doing so far by printing all the filled fields.
```{r}
#print just the non-NULL fields
rmmCleanNULLs(rmm)
```


Check the final object by printing all the filled fields.
```{r}
#print just the non-NULL fields
rmmCleanNULLs(rmm)
# you can also use this function to omit the NULLs at the end of your workflow using, so if you're happy with the above...
rmm <- rmmCleanNULLs(rmm)
```

Now run all availables checks to be sure you're ready to go.
```{r}
rmmCheckFinalize(rmm)
```



